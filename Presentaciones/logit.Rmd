---
output: 
  stevetemplates::beamer:
    keep_tex: TRUE
    latex_engine: pdflatex 
    dev: cairo_pdf 
    slide_level: 3 
    theme: metropolis
title: Regresión Logística
subtitle: Mayo 8, 2024
author: Prof. Sergio Béjar
institute: Departamento de Estudios Políticos, CIDE
fontsize: 10pt
make149: TRUE
# mainfont: "Open Sans Light" # Try out some font options if xelatex
# titlefont: "Titillium Web" # Try out some font options if xelatex
# specify color as six-digit RGB (no pound sign)
# primarycolor: "990000" 
# secondarycolor: "000099"
header-includes:
- \usepackage{booktabs}
- \usepackage{longtable}
- \usepackage{array}
- \usepackage{multirow}
- \usepackage{wrapfig}
- \usepackage{float}
- \usepackage{colortbl}
- \usepackage{pdflscape}
- \usepackage{tabu}
- \usepackage{threeparttable}

---

```{r setup, include=FALSE, cache=F, message=F, warning=F, results="hide"}
knitr::opts_chunk$set(cache=TRUE, warning=F, message=F)
knitr::opts_chunk$set(fig.path='figs/',  fig.width=14, fig.height=8.5)
knitr::opts_chunk$set(cache.path='cache/')

knitr::opts_chunk$set(
                  fig.process = function(x) {
                      x2 = sub('-\\d+([.][a-z]+)$', '\\1', x)
                      if (file.rename(x, x2)) x2 else x
                      }
                  )
```


```{r loaddata, echo=F, eval=T, message=F, warning=F}

library(tidyverse)
library(stevemisc)
library(stevethemes)
library(stevedata)
library(stargazer)
library(modelsummary)
library(kableExtra)
library(lmtest)
library(patchwork)
library(sandwich)
library(readr)


options("modelsummary_format_numeric_latex" = "plain")
options(knitr.kable.NA = '')

set.seed(8675309)
turnout_EU <- rio::import("https://raw.githubusercontent.com/Sergio-Bejar/MCA_CIDE/main/Files/election_turnout.csv") 
anes_prochoice <- rio::import("https://raw.githubusercontent.com/Sergio-Bejar/MCA_CIDE/main/Files/anes_prochoice.csv")
  
  
turnout_EU %>%
  mutate(south = ifelse(region == "South", 1, 0)) -> turnout_EU
```

# Introducción
### Plan para Hoy

*Discutir regresión logística (logit) para variables binarias.*


### Yendo Más lejos en Estadística Aplicada

Ya tenemos herramientas para responder a nuestras propias preguntas en CP/RI. 

- Sabemos como manipular datos.
- Creemos que la variación en  *y* se puede atribuir a la variación en *x*.
- Después de controlar por explicaciones alternativas (*z*), nuestra regresión lineal produce el efecto parcial de *x* en *y*.

La regresión lineal (OLS) nos da la línea que mejor se adapta a los datos.

- Para producir esa linea se minimiza la suma al cuadrado de diferencias al cuadrado (de aquí viene: OLS).

### OLS

OLS tiene muchas propiedades.

- Mejor estimador lineal sin sesgo (BLUE - Best Linear Unbiased Estimator).
- Es fácil de ejecutar y de interpretar.

Sería una *lástima* que algo pasara con alguno de nuestros supuestos.
  
### El Problema de las Variables Dependientes **Binarias**

Uno de los mayores problemas con los que nos podemos encontrar tiene que ver con la variable dependiente. 

- OLS asume que la VD se distribuye normalmente.

Pero en muchas ocasiones nos vamos a encontrar con VDs que son binarias. 

- Candidato gana/pierde.
- Ciudadano votó/no votó.
- Programa exitoso/no exitoso.
- Guerra sucedió/no sucedió.

Muchos fenómenos políticos/sociales se miden con variables binarias ("esta"/"no esta"). 

### Implicaciones cuando Supuestos de OLS son Violados

1. Tus errores serán **heteroesquedásticos.**
2. Tus $\hat{y}$s no harán mucho sentido.


### La Historia de Dos Regresiones

\scriptsize
```{r}

# ¿Cuál fue el % de turnout?
# Vamos a omitir Hawaii y DC porque son outliers potenciales.
M1 <- lm(turnoutho ~ percoled + ss, 
         data=subset(turnout_EU, state %nin% c("Hawaii", "District of Columbia")))

# ¿Ganó Trump (1) o no (0)?
M2 <- lm(trumpw ~ percoled + ss, 
         data=subset(turnout_EU, state %nin% c("Hawaii", "District of Columbia")))

```

\normalsize

###


```{r fitted-resid-m1, echo=F, warning=F}

turnout_EU %>% filter(state %nin% c("Hawaii", "District of Columbia")) %>%
    mutate(fitted = fitted(M1),
           resid = resid(M1)) %>%
    ggplot(.,aes(fitted, resid)) + geom_point()  +
    theme_steve_web() +
    labs(x = "Valores Ajustados",
         y = "Residuales",
         caption = "Modelo linear simple donde turnout es DV y educación universitaria y estado pivotal son vars. explicativas.",
         title = "Un Gráfico de Residuales-Ajustados Debe Verse Así.",
         subtitle = "La variación entre lo que estimamos (fit) y el error que resulta de ello (residuales) es normal.")

```

###

```{r fitted-resid-m2, echo=F, warning=F}

turnout_EU %>% filter(state %nin% c("Hawaii", "District of Columbia")) %>%
    mutate(fitted = fitted(M2),
           resid = resid(M2)) %>%
    ggplot(.,aes(fitted, resid)) + geom_point()  +
    theme_steve_web() +
    labs(x = "Valores Ajustados",
         y = "Residuales",
         caption = "Modelo linear simple donde Gana Trump o no es DV y educación universitaria y estado pivotal son vars. explicativas..",
         title = "Un Gráfico de Residuales-Ajustados NO Debe Verse Así",
         subtitle = "Si ves que hay patrones claros como en este gráfico, OLS no es (con alta probabilidad) el modelo que quieres.")

```

###

```{r fitted-values-m1, echo=F, warning=F}

turnout_EU %>% 
  filter(state %nin% c("Hawaii", "District of Columbia")) %>%
  mutate(fitted = fitted(M1)) %>%
  ggplot(.,aes(fitted)) + 
  theme_steve_web() +
  geom_histogram(bins = 25, color="black", alpha=0.8) +
  scale_x_continuous(limits = c(50, 100), breaks = seq(50, 100, by = 5)) +
  labs(title = "Los Valores Estimados por el Modelo Lineal Deben ser Plausibles",
       x = "Valores Ajustados",
       y = "Cuenta",
       subtitle = "En este ejemplo lo son. Turnout en todos los estados está entre 50s bajos y 70s medios, que es lo que estamos estimando.",
       caption = "Hacer un histograma para una variable continua no es lo mejor, pero lo hago para efectos ilustrativos."
       )

```

###

```{r fitted-values-m2, echo=F, warning=F}
turnout_EU %>% 
  filter(state %nin% c("Hawaii", "District of Columbia")) %>%
  mutate(fitted = fitted(M2)) %>%
  ggplot(.,aes(fitted)) + 
  theme_steve_web() +
  geom_histogram(bins = 25, color="black", alpha=0.8) +
  scale_x_continuous(breaks = seq(-.3, 1.3, by = .1),
                     labels = scales::number_format(accuracy = 0.1)) +
  geom_vline(xintercept = 0, linetype="dashed") +
  geom_vline(xintercept = 1, linetype = "dashed") +
  annotate("rect", xmin = 0, xmax = -Inf, ymin = 0, ymax = Inf,
        alpha = .2) +
  annotate("rect", xmin = 1, xmax = Inf, ymin = 0, ymax = Inf,
        alpha = .2) +
  annotate("text", x = 1.1, y = 5.5, label = "Estimados Imposibles",
           hjust = 0, family = "Open Sans") +
  annotate("text", x = -0.3, y = 5.5, label = "Estimados Imposibles",
           hjust = 0, family = "Open Sans") +
  labs(title = "Los Valores Estimados por el Modelo Lineal deben ser Plausibles",
       x = "Valores Ajustados",
       y = "Cuenta",
       subtitle = "En este ejemplo no lo son. La probabilidad debe estar delimitada entre 0 y 1.",
       caption = ""
       )
```


### ¿Qué Estimados Están Fuera de los Límites?

\scriptsize
```{r}
turnout_EU %>% 
  filter(state %nin% c("Hawaii", "District of Columbia")) %>%
  mutate(fitted = fitted(M2)) %>%
  filter(fitted > 1 | fitted < 0) %>%
  select(state, trumpw, percoled, ss, fitted)

```
\normalsize

### Limitantes con OLS

Substantivamente, los coeficientes de regresión nos llevan a inferencias erróneas.

- Recuerda: Los coeficientes OLS asumen efectos lineales y constantes de *x* en *y*.
- Cuando solo tenemos 0s y 1s, los efectos lineales no son muy intuitivos.

# Regresión Logística
### Regresión Logística

Abordaremos el problema de variables dependientes binarias con la **regresión logística**.

- Nos dará el efecto de un cambio en una unidad de x en la *probabilidad logarítmica natural de y.*

Vamos a empezar viendo que significa la "probabilidad logarítmica natural de y". 

## Odds (Momios)
### Odds (Momios)

La palabra **momios** es muy utilizada en el mundo de las apuestas deportivas. 

- Y está muy relacionada con la probabilidad. 

Dada cierta probabilidad de que un evento *p* ocurra, los momios del evento son iguales a:

$$
\textrm{Momios} = \frac{p}{1-p}
$$

¿Alguna vez escuchaste algo como "los momios son 4 a 1 a favor" del caballo 8?

- Traducción: por cada 5 intentos, esperamos que el caballo 8 gane en 4 ocasiones, en promedio. 

### Educación y Probabilidad de Votar (Datos Hipotéticos)

Vamos a ver esto con unos datos hipotéticos.

```{r, echo=F, eval=T}
tibble(educat = c(rep("0: Low", 100),
                  rep("1: Mid-Low", 100),
                  rep("2: Middle", 100),
                  rep("3: Mid-High", 100),
                  rep("4: High", 100)),
       vote = c(rep(1, 6), rep(0, 94),
                rep(1, 20), rep(0, 80),
                rep(1, 50), rep(0, 50),
                rep(1, 80), rep(0, 20),
                rep(1, 94), rep(0, 6))) -> Fake

Fake %>%
  group_by(educat, vote) %>%
  summarize(n = n()) %>%
  spread(educat, n) %>%
  mutate(vote = c("No", "Yes")) %>%
  bind_rows(., tibble(vote = "Total")) %>%
  rename(Vote = vote) %>%
  mutate_if(is.numeric, ~ifelse(is.na(.), 100, .)) %>%
  kable(., caption = "Educación a nivel individual y Votación (Datos Hipotéticos)",
        format="latex",
        align = c("l","c","c","c","c","c"), booktabs=TRUE, longtable=TRUE) %>%
  row_spec(0, bold=TRUE) %>%
  row_spec(2, hline_after = TRUE) %>%
  row_spec(3, italic = TRUE)
```


- El objetivo aquí es desmenuzar momios y logits en forma accesible.

<!-- \small -->

<!-- | Voto | 0. Bajo | 1. Medio-Bajo | 2. Medio | 3. Medio-Alto | 4. Alto | Total | -->
<!-- |:----:|:-------:|:-----------:|:----------:|:------------:|:--------:|:-----:| -->
<!-- | Sí  | 6  | 20 | 50 | 80 | 94 | 250 | -->
<!-- | No   | 94 | 80 | 50 | 20 | 6 | 250 | -->
<!-- | *N* | 100 | 100 | 100 | 100 | 100 | 500 | -->
<!-- |     |     |     |     |     |     |     | -->
<!-- | p(vote) | .06 | .20 | .50 | .80 | .94 | .50 | -->


### Educación y Probabilidad de Votar

Evidentemente hay una relación positiva.

- i.e. gente más educada tiene una probabilidad más alta de votar.

Pero también estamos viendo la probabilidad de no-linealidad en VDs discretas. 

- El efecto de 0 a 1 en *x* es un cambio de .14 en la probabilidad de votar. 
- De 1 a 2 en *x*: cambio de .30.
- De 2 a 3 en *x*: cambio de .30 de nuevo. 
- De 3 a 4 en *x*: cambio de .14. 

Podemos pensar en algo análogo a un punto de inflexión. 

### Visualizando los Momios

| **Educación**  | **p(votar)** | **Momios de Votar**  |
|:------------|:-------:|:--------------:|
| 0: Bajo    | .06     | .06/.94 = .06  |
| 1: Medio-Bajo  | .20     | .20/.80 = .25  |
| 2: Medio  | .50     | .50/.50 = 1    |
| 3: Medio-Alto | .80     | .80/.20 = 4    | 
| 4: Alto     | .94     | .94/.06 = 16   | 

Table: Probabilidad/Momios de Educación y Votar (Datos Hipotéticos)

### Visualizando Momios

La columna derecha, momios de votar, convierte probabilidades a momios.

- e.g.  $\frac{p}{1-p}$ cuando *x* = 0 = $\frac{.06}{.94}$ = .06382979.
- Una vez que llegamos a la categoria "Medio", los momios son enteros.
	- Cuando los momios son igual a 1, esperamos un votante por cada no-votante.
	
## Relación de Momios (Odds Ratio)
### Relación de Momios (Odds Ratio)

Una forma en la que podemos ver como *x* afecta a *y* es utilizando la **relación de momios (odds ratio)**.


### Momios y Relación de Momios

Veamos a la tabla.

- Momios de votar en la categoria de educación baja: .06.
- Momios de votar en la categoria de educación media-baja: .25. 

Los momios de votar para la categoria media-baja son más de cuatro veces los momios de votar en la categoría de educación baja. 


- $\frac{.25}{.06}$ = 4.1$\overline{6}$
- Hagan esto para todos los otros valores y la relación de momios va a ser 4 siempre. 

$$
\textrm{Odds ratio} = \frac{1}{.25} = \frac{4}{1} = \frac{16}{4} = 4
$$

### Cambio Porcentual en Momios

También podemos calcular el **cambio porcentual en momios**.

### Cambio Porcentual en Momios

Vamos a considerar de nuevo los momios de votar en las dos categorias más bajas. 


- Calcular el incremento de unidad (aquí: .25 - .06 = .19).
- Dividimos eso entre los momios del valor más bajo (aquí: .06)
- Esto nos da un valor de 3.1$\overline{6}$.
- Multiplicamos eso por 100 para obtener el cambio porcentual

Si hacemos esto para todos los otros valores, obtendremos valores de 3 (i.e. 300%).

## Logits (Natural Logged Odds de y)
### Logits (Natural Logged Odds de *y*)

Hemos visto que cada unidad de cambio en *x* no produce un cambio consistente en *y*. 

- Pero, el efecto del cambio en la relación de momios y cambio porcentual es consistente. 
- El siguiente paso es hacer la transformación logarítmica natural de los momios, o **logit**. 


### Transformación Logarítmica Natural

El término clave aquí es transformación *natural* logarítmica. 

En cálculo, el logaritmo natural con base *e* es común. 


### Pregunta

$$
f(x) = (1 + \frac{1}{x})^{x}
$$

¿Qué pasa en esta fórmula cuando *x* se va hacia el infinito?



### Transformación Logarítmica Natural

Cuando *x* tiende al infinito, el exponente tiene también al infinito.

- Sin embargo, el denominador también.

Esto significa que estaremos tomando el exponencial de infinito para un valor cercano a 1, que resulta básicamente en 1.

- Bernoulli descubrió que el límite está entre 2 y 3.

Leonhard Euler propuso que la respuesta es *e* (un número irracional) y lo podemos denotar como *e* = 2.7182818284, aproximadamente.

### Transformación Logarítmica Natural

Tomamo el logaritmo natural de todos los momios de *y* y lo agregamos a nuestra table. 

| **Educación**  | **p(votar)** | **Momios de Votar**  | **Momios Logged** |
|:------------|:-------:|:--------------:|:-----------:|
| 0: Low      | .06     | .06/.94 = .06  | -2.8      |
| 1: Mid-low  | .20     | .20/.80 = .25  | -1.4      |
| 2: Middle   | .50     | .50/.50 = 1    | 0           |
| 3: Mid-high | .80     | .80/.20 = 4    | 1.4       |
| 4: High     | .94     | .94/.06 = 16 | 2.8       |

Table: Probabilidad, Momios, y Logits de Educación y Votar (Datos Hipotéticos)

## Regresión Logística
### Regresión Logística

Nuestra *y* no nada más es 0s y 1s, sino funciones logit aplicadas a los momios de 0s y 1s para todos los valores de *x*. Formalmente:


$$
\textrm{Momios logged de $y$} =  \hat{a} + \hat{b}(x)
$$

¿Cómo se vería esto en el ejemplo simple que estamos viendo? 


### Regresión Logística

$$
\textrm{Momios logged de votar} = -2.8 + 1.4(x)
$$

Recordemos que:

- $\hat{a}$ es el estimado de los momios logged de *y* cuando *x* = 0 (entonces: -2.8)
- 1.4 es el $\hat{b}$ que observamos en la columna derecha de la tabla. 

### Interpretación de Regresión Logística

Una unidad de incremento en *x* resulta en un incremento de 1.4 en los momios logged de *y*. 

- Aunque esto es una interpretación correcta, no es muy intuitiva. 

¿Cómo obtenemos una interpretación más digestible/substantiva? 


### Interpretación de Regresión Logística

"Exponenciamos" el coeficiente de nuestra regresión.

$$
\textrm{Exp}(\hat{b}) = \textrm{Exp}(1.4) = e^{1.4} = 4
$$
¿Se ve familiar ese 4?


### Interpretación de Regresión Logística

*Es la relación de momios*.

- Recuerda: tu coeficiente de regresión es el estimado del tamaño del efecto de una unidad a otra (más alta) en todo el rango de *x*. 

### Interpretación de Regresión Logística 

También podemos obtener el cambio porcentual en los momios. 


$$
\textrm{Cambio porcentual en los momios de $y$} = 100*(\textrm{Exp}(\hat{b}) - 1)
$$


Con estos datos, obtenemos un resultado de 300.  Cada incremento de unidad en $x$ (en este caso: educación) incrementa los momios de votar en un 300 por ciento. 

### Interpretando Regresión Logística

También podemos obtener probabilidades (por ejemplo: cuando *x* = 0)


$$
	\textrm{Probabilidad} = \frac{\textrm{Momios}}{1 + \textrm{Momios}} = \frac{e^{-2.8}}{1 + e^{-2.8}} = .06
$$

### ...o en R

```{r}

exp(-2.8)/(1 + exp(-2.8))
plogis(-2.8)  # hagan esto mejor

```

### Ahora Con Datos Reales

¿Cómo se vería esto con datos reales?  Vamos a hacer un ejemplo con datos del General Social Survey, olas 2016 y 2018. 


- *y*: ¿Pueden las mujeres obtener un aborto legal por alguna razón?

###

```{r showabany, echo=F, eval=T, warning=F, results="asis"}

gss_abortion %>%
  filter(year >= 2016) %>%
  group_by(abany) %>%
  summarize(n = n()) %>% 
  na.omit %>%
  mutate(xcat = c("No", "Sí"),
         porc = n/sum(n),
         lab = paste0(mround(porc), "%")) %>%
  select(xcat, n, lab) %>%
  kable(., caption = "¿Pueden las mujeres obtener un aborto legal por alguna razón? (GSS, 2016-2018)",
        col.names = c("Respuesta","No. de Observaciones","Porcentaje"),
        format="latex",
        align = c("l","c","c"), booktabs=TRUE, longtable=TRUE) %>%
  row_spec(0, bold=TRUE)

```

### Variables Explicativas 

- Mujer (1 = mujer)
- Efectos Fijos para Raza (blancos [omitidos], afro-americanos, otros)
- Hispano (1 = sí)
- Nivel Educativo (años en escuela [0:20])
- ID Partidario (muy D a muy R [0:6])
- Actividad Religiosa (nunca a varias veces al día [0:10])

###

\scriptsize

```{r, echo=T, eval= F}

gss_abortion %>%
  filter(year >= 2016) %>%
  mutate(race = fct_relevel(race, "White"),
         relactiv = relactiv - 1,
         female = ifelse(sex == "Female", 1, 0)) -> Data

M3 <- glm(abany ~ female + factor(race) + hispanic + educ + 
            pid + relactiv, data=Data,
          family=binomial(link="logit"))

modelsummary(list("¿Se puede abortar por alguna razón?" = M3), output="latex",
             title = "Actitudes sobre Aborto en GSS (2016-2018)",
             stars = TRUE, gof_omit = "IC|F|Log.|R2$",
             coef_map = c("female" = "Mujer",
                          "factor(race)Black" = "Raza = Afro-Americano",
                          "factor(race)Other" = "Raza = Otra",
                          "hispanic" = "Hispano",
                          "educ" = "Años de Educación",
                          "pid7" = "ID Partidario (D to R)",
                          "relactiv" = "Actividad Religiosa",
                          "(Intercept)" = "Intercepto"),
             align = "lc")

```
\normalsize

###

\scriptsize
```{r model1, echo=F, eval=T, results="asis"}

gss_abortion %>%
  filter(year >= 2016) %>%
  mutate(race = fct_relevel(race, "White"),
         relactiv = relactiv - 1,
         female = ifelse(sex == "Female", 1, 0)) -> Data

M3 <- glm(abany ~ female + factor(race) + hispanic + educ + 
            pid + relactiv, data=Data,
          family=binomial(link="logit"))

modelsummary(list("¿Se puede abortar por alguna razón?" = M3), output="latex",
             title = "Actitudes sobre Aborto en GSS (2016-2018)",
             stars = TRUE, gof_omit = "IC|F|Log.|R2$",
             coef_map = c("female" = "Mujer",
                          "factor(race)Black" = "Raza = Afro-Americano",
                          "factor(race)Other" = "Raza = Otra",
                          "hispanic" = "Hispano",
                          "educ" = "Años de Educación",
                          "pid7" = "ID Partidario (D to R)",
                          "relactiv" = "Actividad Religiosa",
                          "(Intercept)" = "Intercepto"),
             align = "lc")

```

\normalsize

### Interpretación de Tabla 5

- No hay diferencia significativa entre mujeres y hombres. 
- Los afro-americanos son menos propensos a pensar que las mujeres deberían poder abortar por alguna razón que los blancos.  
- No hay diferencua entre otras razas (i.e. Asiáticos) y blancos. 
- Los Hispanos son menos propensos a estar a favor del aborto por cualquier razón. 
- La educación tiene un efecto positivo. 
- Ser Republicano y religioso disminuye la propensidad a contestar "sí". 

### Extrayendo Algunas Cantidades de Interés. 

Digamos que nos interesa entender el efecto de ser Hispano. 


- Exp(-0.354) = $e^{-0.354}$ = .701. Esto es la relación de momios (Odds Ratio). 
- 100*($e^{-0.354}$ - 1) = -29.81%. El cambio porcentual en los momios de estar a favor del aborto por cualquier razón. 

Ahora veamos el efecto de un incremento en educación.

- Relación de momios (Odds ratio): $e^{.153}$ = 1.165.
- Probabilidad de cambio en momios: 100*($e^{.153}$ - 1) = 16.53%

El intercepto también da información útil ($\hat{a}$ = -.895).

- Nos dice los momios logged de contestar "sí" para un individuo que es blanco, no-hispano, muy demócrata y que nunca va a servicios religiosos.

- La probabilidad de que esa persona conteste "sí" es: .290

# Conclusión
### Conclusión

Las variables dependientes binarias violan supuestos de OLS y producen estimados engañosos. 

- Por eso utilizamos regresión logística.
- El proceso de inferencia es el mismo, pero los coeficientes comunican cosas algo diferentes. 
- Es la misma regresión, solo que sobre una VD transformada. 

La compu hace el trabajo duro por nosotros, pero es importante saber que es lo que la compu está haciendo en este caso. 





